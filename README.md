# Fine-tune GPT model on wikitext data

This Github repo demonstrated using wikitext data for fine-tuning GPT2 model language model. The same code can be applied to other language models. For demonstration purposes, we use GPT2 model since it is smaller.

To launch the virtual environment, just do
''' . env.sh'''


