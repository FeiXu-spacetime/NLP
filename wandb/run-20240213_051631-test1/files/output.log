
  0%|                                                                                                                                     | 0/230 [00:00<?, ?it/s]
epoch_idx: 0
  0%|                                                                                                                                     | 0/230 [00:00<?, ?it/s]/home-nfs/fx2024/mc3/envs/fei-venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|▌                                                                                                                            | 1/230 [00:05<19:16,  5.05s/it]
loss tensor(40.5234, device='cuda:0', grad_fn=<SumBackward0>)
epoch_idx: 0
batch_idx: 1

  1%|█                                                                                                                            | 2/230 [00:07<13:51,  3.65s/it]
epoch_idx: 0
batch_idx: 2

loss tensor(3.9555, device='cuda:0', grad_fn=<SumBackward0>)
epoch_idx: 0
batch_idx: 3

loss tensor(0.9115, device='cuda:0', grad_fn=<SumBackward0>)
epoch_idx: 0
batch_idx: 4
loss tensor(1.2255, device='cuda:0', grad_fn=<SumBackward0>)
Program interrupted. (Use 'cont' to resume).
--Return--
> /home-nfs/fx2024/mc3/envs/fei-venv/lib/python3.11/site-packages/torch/cuda/memory.py(162)empty_cache()->None
-> torch._C._cuda_emptyCache()
